{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision as tv\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "\n",
    "transform = tv.transforms.Compose([\n",
    "    tv.transforms.Grayscale(num_output_channels=1),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "trainset = tv.datasets.ImageFolder(os.path.join(data_dir, 'train'),\n",
    "                                   transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)\n",
    "\n",
    "testset = tv.datasets.ImageFolder(os.path.join(data_dir, 'test'),\n",
    "                                   transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)\n",
    "\n",
    "class_names = trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,\n",
    "        conv1_out_chnls,\n",
    "        conv1_ker_size,\n",
    "        pool1_ker_size,\n",
    "        conv2_out_chnls,\n",
    "        conv2_ker_size,\n",
    "        pool2_ker_size,\n",
    "        fc1_lin,\n",
    "        fc2_lin\n",
    "    ):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, conv1_out_chnls, conv1_ker_size)\n",
    "        self.pool1 = nn.MaxPool2d(pool1_ker_size)\n",
    "        self.conv2 = nn.Conv2d(conv1_out_chnls, conv2_out_chnls, conv2_ker_size)\n",
    "        self.pool2 = nn.MaxPool2d(pool2_ker_size)\n",
    "        self.fc1 = nn.Linear(conv2_out_chnls * pool2_ker_size**2, fc1_lin)\n",
    "        self.fc2 = nn.Linear(fc1_lin, fc2_lin)\n",
    "        self.fc3 = nn.Linear(fc2_lin, len(class_names))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 30 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "VERSION = '01'\n",
    "PATH = f'./nets/chinese_classifier_net_{VERSION}.pth'\n",
    "\n",
    "PARAMS = {\n",
    "    'conv1_out_chnls' : 12,     # layer 1: convultional\n",
    "    'conv1_ker_size' : 5,\n",
    "    'pool1_ker_size' : 3,       # layer 2: max pool\n",
    "    'conv2_out_chnls' : 30,     # layer 3: convultional\n",
    "    'conv2_ker_size' : 5,\n",
    "    'pool2_ker_size' : 4,       # layer 4: max pool\n",
    "    'fc1_lin' : 256,            # layer 5: linear\n",
    "    'fc2_lin' : 64              # layer 6: linear\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net( *PARAMS.values() )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.002, momentum=0.9)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'using: {device}')\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs=2):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Starting epoch: {epoch}')\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 1000 == 999:\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 1000:.3f}')\n",
    "                running_loss = 0\n",
    "    \n",
    "    print('Training: Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "\n",
    "if TRAIN:\n",
    "    train()\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "else:\n",
    "    net = Net(*PARAMS.values())\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate\n",
    "print('Start validation')\n",
    "\n",
    "class_correct = {name: 0. for name in class_names}\n",
    "class_total =   {name: 0. for name in class_names}\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct = (predicted == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i].item()\n",
    "                class_correct[class_names[label]] += correct[i].item()\n",
    "                class_total[class_names[label]] += 1\n",
    "\n",
    "accuracies = {name : 100 * class_correct[name] / class_total[name] for name in class_names}\n",
    "\n",
    "for name, accuracy in accuracies.items():\n",
    "    print(f'Accuracy of {name} : {accuracy:2.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving results to file\n",
    "results_dir = 'results.csv'\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    with open(results_dir, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = ['version', *PARAMS.keys(), *class_names]\n",
    "        writer.writerow(header)\n",
    "\n",
    "with open(results_dir, 'a', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([VERSION, *PARAMS.values(), *accuracies.values()])\n",
    "print('Saved to results file')"
   ]
  }
 ]
}